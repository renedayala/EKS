{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6547581-eab1-41d3-861a-5972f485194d",
   "metadata": {},
   "source": [
    "# [Draft] STG406 - ML Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dce682-1524-4183-aceb-e608cee48de6",
   "metadata": {},
   "source": [
    "This is an evolving notebook to collaborate and develop ML part of STG406 workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77af8dd-b4c3-44f4-bf32-af2ef6c52aad",
   "metadata": {},
   "source": [
    "## (Optional) Create synthetic dataset and store it on S3\n",
    "\n",
    "> ⚠️ Note: this step will likely NOT be part of this notebook. This optional step is provided here for convenience of dev work only, and is meant to setup a minimal benchmark environment for testing w/o leaving this NB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1db8c3-db7c-4341-ba86-9ea7d9584c7a",
   "metadata": {},
   "source": [
    "#### Clone the SageMaker Bencher repo to bootstrap S3\n",
    "\n",
    "We will only use the capability of SageMaker Bencher to automatically create synthetic datasets and upload them to S3. No other actions will be performed by SageMaker Bencher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0077921-06ce-46b7-9af4-86840360f21c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'sagemaker-bencher' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aws-samples/sagemaker-bencher.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bac317-7071-42f4-8ebd-1d17e0e78a9b",
   "metadata": {},
   "source": [
    "#### Install all Python modules to run SageMaker Bencher locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2653c9d-ea0f-48d6-bbe2-506d0793f2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -r sagemaker-bencher/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07475f-a3d4-4e84-9737-fd0bf0869b7f",
   "metadata": {},
   "source": [
    "#### Staging synthetic data in S3 bucket\n",
    "> ⚠️ Note: before continuing, make sure set the desired AWS region for the S3 staging bucket in the YAML file below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "918eb96c-f199-4e1a-92e4-23b3ba7eced5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sagemaker-bencher/experiments/stg406-bootstrap-s3.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile sagemaker-bencher/experiments/stg406-bootstrap-s3.yml\n",
    "\n",
    "# --- MAIN EXPERIMENT SETTINGS\n",
    "name: dummy\n",
    "role: dummy\n",
    "region: us-west-2\n",
    "output_prefix: dummy\n",
    "bucket: workshop-us-west-2-277453393386\n",
    "\n",
    "parallelism: 0\n",
    "\n",
    "# --- DATASET DEFINITIONS\n",
    "datasets:\n",
    "    Synth-jpg-10GB-a-100KB:\n",
    "        type: synthetic\n",
    "        format: jpg\n",
    "        bucket: workshop-us-west-2-277453393386\n",
    "        prefix: 'datasets/synthetic'\n",
    "        dimension: [290, 290, 3]\n",
    "        num_files: 10000\n",
    "        num_copies: 10\n",
    "        num_classes: 4\n",
    "\n",
    "    Synth-jpg-5GB-a-100KB:\n",
    "        type: synthetic\n",
    "        format: jpg\n",
    "        bucket: workshop-us-west-2-277453393386\n",
    "        prefix: 'datasets/synthetic'\n",
    "        dimension: [290, 290, 3]\n",
    "        num_files: 10000\n",
    "        num_copies: 5\n",
    "        num_classes: 4\n",
    "\n",
    "    Synth-jpg-100MB-a-100KB:\n",
    "        type: synthetic\n",
    "        format: jpg\n",
    "        bucket: workshop-us-west-2-277453393386\n",
    "        prefix: 'datasets/synthetic'\n",
    "        dimension: [290, 290, 3]\n",
    "        num_files: 1000\n",
    "        num_copies: 1\n",
    "        num_classes: 4\n",
    "    \n",
    "    Synth-tar-jpg-10GB-a-100MB:\n",
    "        type: synthetic\n",
    "        format: tar/jpg\n",
    "        bucket: workshop-us-west-2-277453393386\n",
    "        prefix: 'datasets/synthetic'\n",
    "        dimension: [290, 290, 3]\n",
    "        num_records: 1000\n",
    "        num_files: 10\n",
    "        num_copies: 10\n",
    "        num_classes: 4\n",
    "\n",
    "    Synth-tar-jpg-5GB-a-100MB:\n",
    "        type: synthetic\n",
    "        format: tar/jpg\n",
    "        bucket: workshop-us-west-2-277453393386\n",
    "        prefix: 'datasets/synthetic'\n",
    "        dimension: [290, 290, 3]\n",
    "        num_records: 1000\n",
    "        num_files: 10\n",
    "        num_copies: 5\n",
    "        num_classes: 4\n",
    "\n",
    "    100k-samples-small-files:\n",
    "        type: synthetic\n",
    "        format: jpg\n",
    "        bucket: workshop-us-west-2-277453393386\n",
    "        prefix: 'datasets/synthetic'\n",
    "        dimension: [290, 290, 3]\n",
    "        num_files: 10000\n",
    "        num_copies: 10\n",
    "        num_classes: 4\n",
    "\n",
    "\n",
    "# --- TRIAL DEFINITIONS\n",
    "# Default values for trials (if not overriden by specific trial)\n",
    "base_trial:\n",
    "  script: benchmark-tensorflow.py\n",
    "\n",
    "\n",
    "# Trial definitions\n",
    "trials:\n",
    "\n",
    "  - inputs:\n",
    "      train:\n",
    "        dataset: Synth-jpg-10GB-a-100KB\n",
    "\n",
    "  - inputs:\n",
    "      train:\n",
    "        dataset: Synth-jpg-100MB-a-100KB\n",
    "\n",
    "  - inputs:\n",
    "      train:\n",
    "        dataset: 100k-samples-small-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4336f9ab-c6d7-4b5c-a6e7-91d6f5e467d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/jupyter-admin/.config/sagemaker/config.yaml\n",
      "2024-10-29 15:49:58.539257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730216998.556987   55985 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730216998.562400   55985 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 15:49:58.580433: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "SageMaker SDK: 2.232.2\n",
      "Building the datasets for 'dummy' experiment..\n",
      "Dataset 'Synth-jpg-10GB-a-100KB' found on 's3://workshop-us-west-2-277453393386/datasets/synthetic/Synth-jpg-10GB-a-100KB'. Skipping build..\n",
      "Dataset 'Synth-jpg-100MB-a-100KB' found on 's3://workshop-us-west-2-277453393386/datasets/synthetic/Synth-jpg-100MB-a-100KB'. Skipping build..\n",
      "Building dataset '100k-samples-small-files'..\n",
      "[100k-samples-small-files] Staging dataset in '/tmp/tmpmx435x6y'..\n",
      "100%|████████████████████████████████████| 10000/10000 [01:15<00:00, 132.11it/s]\n",
      "[100k-samples-small-files] Uploading dataset to 's3://workshop-us-west-2-277453393386/datasets/synthetic/100k-samples-small-files'..\n",
      "100%|██████████████████████████████████| 100000/100000 [04:20<00:00, 383.58it/s]\n",
      "Experiment finished in: 337.27876901626587 sec..\n"
     ]
    }
   ],
   "source": [
    "!python sagemaker-bencher/bencher.py -f sagemaker-bencher/experiments/stg406-bootstrap-s3.yml --bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c5036c-5aa4-4594-b7aa-6894bc45ffc1",
   "metadata": {},
   "source": [
    "## Benchmark training job setup\n",
    "\n",
    "### Create the remotely runnable Python training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1ab2c-bea2-423d-8396-fbd9b7c546ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile scripts/benchmark_dev.py\n",
    "\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import webdataset as wds\n",
    "#import s3torchconnector as s3pt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchdata\n",
    "from torchvision.transforms import v2 as tvt\n",
    "#from transformers import ViTForImageClassification\n",
    "\n",
    "import ray.train.torch\n",
    "\n",
    "\n",
    "################## BENCHMARK PARAMETERS DEFINITION ###################\n",
    "\n",
    "def parse_args():\n",
    "    \n",
    "    def none_or_int(value):\n",
    "        if str(value).upper() == 'NONE':\n",
    "            return None\n",
    "        return int(value)\n",
    "    \n",
    "    def none_or_str(value):\n",
    "        if str(value).upper() == 'NONE':\n",
    "            return None\n",
    "        return str(value)\n",
    "    \n",
    "    def str_bool(value):\n",
    "        if str(value).upper() == 'TRUE':\n",
    "            return True\n",
    "        elif str(value).upper() == 'FALSE':\n",
    "            return False\n",
    "        else:\n",
    "            raise TypeError(\"Must be True or False.\")\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    ### Parameters that define dataloader part \n",
    "    parser.add_argument('--batch_size', type=int, default=64)\n",
    "    parser.add_argument('--num_workers', type=int, default=0)\n",
    "    parser.add_argument('--prefetch_size', type=none_or_int, default=0)\n",
    "    parser.add_argument('--input_dim', type=int, default=224)\n",
    "    parser.add_argument('--pin_memory', type=str_bool, default=True)\n",
    "    parser.add_argument('--batch_drop_last', type=str_bool, default=False)\n",
    "    \n",
    "    ### Parameters that define computation part \n",
    "    parser.add_argument('--epochs', type=int, default=1)\n",
    "    parser.add_argument('--compute_time', type=none_or_int, default=None) # in MS\n",
    "    parser.add_argument('--num_nodes', type=int, default=2)\n",
    "   \n",
    "    ### Parameters that define some storage and dataset details for benchmarking \n",
    "    #parser.add_argument('--bucket_mount_path', type=str)\n",
    "    #parser.add_argument('--bucket_dataset_prefix', type=str)\n",
    "    parser.add_argument('--dataset_path', type=str)\n",
    "    parser.add_argument('--dataset_format', type=str)\n",
    "    parser.add_argument('--dataset_num_samples', type=int, default=100000)\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "################## MODEL IMPLEMENTATION ###################\n",
    "\n",
    "class ModelMock(torch.nn.Module):\n",
    "    '''Model mock to emulate a computation of a training step'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dummy_module = torch.nn.Linear(10, 10)\n",
    "        self.config = config\n",
    "    \n",
    "    def forward(self, data, target, batch_idx):\n",
    "        if self.config.compute_time > 0:\n",
    "            return time.sleep(self.config.compute_time / 1000)\n",
    "        return \n",
    "\n",
    "\n",
    "################## DATASET IMPLEMENTATIONS ###################\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "class MapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files, transform):\n",
    "        self._files = np.array(files)\n",
    "        self._transform = transform\n",
    "   \n",
    "    @staticmethod\n",
    "    def _get_label(file):\n",
    "        return file.split(os.path.sep)[-2]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _read(file):\n",
    "        return Image.open(file).convert('RGB')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file = self._files[idx]\n",
    "        sample = self._transform(self._read(file))\n",
    "        label = int(self._get_label(file))    # Labels in [0, MAX) range\n",
    "        return sample, label\n",
    "\n",
    "def _make_pt_dataset(config, transform):\n",
    "    files = glob.glob(config.dataset_path + '/**/*.jpg')\n",
    "    dataset = MapDataset(files, transform)\n",
    "    return dataset\n",
    "\n",
    "def _make_wds_dataset(config, transform):\n",
    "    files = glob.glob(config.dataset_path + '/*.tar')        \n",
    "    dataset = wds.WebDataset(files, shardshuffle=True, resampled=True, nodesplitter=wds.split_by_node)\n",
    "    dataset = dataset.decode('pil')\n",
    "    dataset = dataset.to_tuple('jpg', 'cls')\n",
    "    dataset = dataset.map_tuple(transform, identity)\n",
    "    #dataset = dataset.with_length(config.dataset_num_samples)\n",
    "    dataset = dataset.with_epoch(config.dataset_num_samples // (config.num_nodes * config.num_workers))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "################## BENCHMARK IMPLEMENTATIONS #################\n",
    "\n",
    "def build_dataloader(config):\n",
    "\n",
    "    transform = tvt.Compose([\n",
    "        tvt.ToImage(),\n",
    "        tvt.ToDtype(torch.uint8, scale=True),\n",
    "        tvt.RandomResizedCrop(size=(config.input_dim, config.input_dim), antialias=False), #antialias=True\n",
    "        tvt.ToDtype(torch.float32, scale=True),\n",
    "        tvt.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Build dataset\n",
    "    if config.dataset_format == 'jpg':\n",
    "        dataset = _make_pt_dataset(config, transform)\n",
    "    elif config.dataset_format == 'tar':\n",
    "        dataset = _make_wds_dataset(config, transform)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown dataset format '%s'..\" % config.dataset_format)\n",
    "\n",
    "\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        num_workers=config.num_workers,\n",
    "        batch_size=config.batch_size,\n",
    "        prefetch_factor=config.prefetch_size,\n",
    "        pin_memory=config.pin_memory\n",
    "    )\n",
    "\n",
    "\n",
    "def build_model(config):\n",
    "    if config.compute_time is not None:\n",
    "        model = ModelMock(config)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Compute time parameter must be set explicitly..\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, config):\n",
    "    metrics = {}\n",
    "    img_tot_list, ep_times, ckpt_times = [], [], []\n",
    "    t_train_start = t_epoch_start = time.perf_counter()\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "\n",
    "        if config.num_nodes > 1:\n",
    "            dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        img_tot = 0\n",
    "        for iteration, (images, labels) in enumerate(dataloader, 1):\n",
    "                \n",
    "            # do training step\n",
    "            batch_size = len(images)\n",
    "            img_tot += batch_size\n",
    "\n",
    "            result = model(images, labels, iteration)\n",
    "\n",
    "            if result:\n",
    "                ckpt_times.append(result)\n",
    "\n",
    "            if iteration % 50 == 0:\n",
    "                #print(iteration, '-->', images.shape, labels.shape, labels)\n",
    "                print(\"Epoch =\", epoch, \"/ Iteration =\", iteration)\n",
    "\n",
    "        # log metrics\n",
    "        img_tot_list.append(img_tot)\n",
    "        ep_times.append(time.perf_counter() - t_epoch_start)\n",
    "        t_epoch_start = time.perf_counter()\n",
    "\n",
    "    # log metrics\n",
    "    t_train_tot = time.perf_counter() - t_train_start\n",
    "    metrics['t_training_exact'] = t_train_tot\n",
    "    metrics['img_sec_ave_tot'] = sum(img_tot_list) / t_train_tot\n",
    "    metrics['img_tot'] = sum(img_tot_list)\n",
    "    metrics.update({f't_epoch_{i}': t for i, t in enumerate(ep_times, 1)})\n",
    "    metrics.update({f't_ckpt_{i}': t for i, t in enumerate(ckpt_times, 1)})\n",
    "    return metrics\n",
    "    \n",
    "\n",
    "def main(config):\n",
    "\n",
    "    # Debug\n",
    "    files = glob.glob(config.dataset_path + '/**/*.jpg')\n",
    "    \n",
    "    print(\"Dataset files:\")\n",
    "    for i, f in enumerate(files):\n",
    "        print(' -', f)\n",
    "        if i > 20: break\n",
    "    \n",
    "\n",
    "    # Log params\n",
    "    print(\"Benchmarking params:\\n\" + json.dumps(vars(config), indent=2))\n",
    "    \n",
    "    # Build dataloader\n",
    "    dataloader = build_dataloader(config)\n",
    "    dataloader = ray.train.torch.prepare_data_loader(dataloader)\n",
    "\n",
    "    # Build model\n",
    "    model = build_model(config)\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    # Do training run\n",
    "    metrics = train_model(model, dataloader, config)\n",
    "    \n",
    "    # Finish\n",
    "    print(\"All logged metrics:\\n\" + json.dumps(metrics, indent=2))\n",
    "    time.sleep(3)\n",
    "\n",
    "    return\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Step 1: Parse the parameters sent by the SageMaker client to the script\n",
    "    train_config, unknown = parse_args()\n",
    "\n",
    "    scaling_config = ray.train.ScalingConfig(num_workers=train_config.num_nodes, use_gpu=False)\n",
    "    \n",
    "    trainer = ray.train.torch.TorchTrainer(\n",
    "        main,\n",
    "        scaling_config=scaling_config,\n",
    "        train_loop_config=train_config)\n",
    "\n",
    "    result = trainer.fit()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "736fdcef-70f1-4613-9f5e-9bd7457071eb",
   "metadata": {},
   "source": [
    "### Run remotely on Ray\n",
    "\n",
    "**Note**: remote pods will have to be bootstraped by installing these packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047196a-2ba3-4149-9293-e0d5bdb62e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ray.job_submission import JobSubmissionClient, JobStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9e852-ddab-490d-aa72-6279962e7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_head_dns = \"ws-ray-head-nlb-76930d7bd7033359.elb.eu-central-1.amazonaws.com\"\n",
    "ray_head_port = 8265\n",
    "ray_address = f\"http://{ray_head_dns}:{ray_head_port}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb1df8-0654-4f13-9eb0-dc104e06a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = JobSubmissionClient(ray_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b9045-9dca-4a91-9085-218904e9ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_dataset_dir = '/mnt/default'\n",
    "# local_dataset_dir = '/mnt/metadata-cache'\n",
    "# local_dataset_dir = '/mnt/full-cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0d5e3-857b-4ca1-9e2b-193b8ad01029",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrypoint_cmd = \"python benchmark_dev.py\" \\\n",
    "                 \" --epochs=3\" \\\n",
    "                 \" --num_workers=12\" \\\n",
    "                 \" --num_nodes=2\" \\\n",
    "                 \" --prefetch_size=2\" \\\n",
    "                 \" --compute_time=0\" \\\n",
    "                 \" --dataset_path=/mnt/full-cache/datasets/synthetic/Synth-jpg-5GB-a-100KB\" \\\n",
    "                 \" --dataset_format=jpg\"\n",
    "                 \n",
    "\n",
    "job_id = client.submit_job(\n",
    "    entrypoint=entrypoint_cmd,\n",
    "    runtime_env={\n",
    "        \"working_dir\": \"./scripts\",\n",
    "        \"pip\": ['torch', 'torchvision', 'torchdata', 'webdataset'],\n",
    "        \"env_vars\": {'RAY_DEDUP_LOGS': '0'}}\n",
    ")\n",
    "\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4c3f5-3a7d-40d5-ace9-0fa910ae1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab532c-2acf-4f76-8359-852d9b5dca3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
